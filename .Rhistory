# save the url as a variable
apiOutput <- getURL(station_link)
# get the text from that url
apiData <- fromJSON(apiOutput)
# read text, parsing as a json file
stationStatus <- apiData$data$stations
# extract a dataframe from a list object of R and save as 'stationStatus'
cols <- c('num_bikes_disabled','num_docks_disabled', 'station_id',
'num_ebikes_available', 'num_bikes_available', 'num_docks_available')
# save column names we are going to name the new dataframe
stationStatus = stationStatus[,cols]
# do the naming part
str(apiOutput)
str(apiData)
# The 'apiOutput' is pure text, saved as large characters
# The 'apiData' is a structured 'list' varaible of R
# prettify(apiOutput)
# This function makes the large character of original json file somewhat readable but still not enough, and due to the length of result showing, I'm going to mute it
str(stationStatus)
# This dataframe has the information of the numbers of different bikes, ebikes and docks available or not at each stations, identified by station_id. Only station_id is character while other factors are all saved as integer.
hist(stationStatus$num_docks_available)
hist(stationStatus$num_bikes_available)
# nrow(unique(stationStatus%>%filter(stationStatus$num_ebikes_available>=1)))
nrow(unique(stationStatus[stationStatus$num_ebikes_available>0,]))
station_1more_ebike=stationStatus[stationStatus$num_ebikes_available>=1,]
mean(station_1more_ebike$num_docks_available)
mean(stationStatus$num_docks_available)
# These two means are different with an absolute value of about 1
stationStatus$stationSize=stationStatus$num_ebikes_available+
stationStatus$num_bikes_available+
stationStatus$num_docks_available+
stationStatus$num_bikes_disabled+
stationStatus$num_docks_disabled
hist(stationStatus$stationSize)
plot(stationStatus$num_docks_disabled,stationStatus$num_bikes_available)
# disabled docks don't mean it's occupied
plot(stationStatus$num_docks_available-stationStatus$num_docks_disabled,stationStatus$num_bikes_available)
# disabled docks don't mean it's occupied
stationStatus$occupied_docks=stationStatus$stationSize-stationStatus$num_docks_available-stationStatus$num_docks_disabled
stationStatus$occupied_docks=stationStatus$stationSize-stationStatus$num_docks_available-stationStatus$num_docks_disabled
plot(stationStatus$occupied_docks,stationStatus$num_bikes_available)
# disabled docks don't mean it's occupied
stationStatus$Bike_all=stationStatus$num_ebikes_available+stationStatus$num_bikes_available
# Occupied dock numbers are similar to available bike numbers
plot(stationStatus$occupied_docks,stationStatus$Bike_all)
# Enter your name here: Hang Tian
# 1. I did this lab assignment by myself, with help from the book and the professor.
library('RCurl')
library('jsonlite')
library(tidyverse)
station_link <- 'https://gbfs.citibikenyc.com/gbfs/en/station_status.json'
apiOutput <- getURL(station_link)
apiData <- fromJSON(apiOutput)
stationStatus <- apiData$data$stations
cols <- c('num_bikes_disabled','num_docks_disabled', 'station_id',
'num_ebikes_available', 'num_bikes_available', 'num_docks_available')
stationStatus = stationStatus[,cols]
# Plain text with '{}'s
station_link <- 'https://gbfs.citibikenyc.com/gbfs/en/station_status.json'
# save the url as a variable
apiOutput <- getURL(station_link)
# get the text from that url
apiData <- fromJSON(apiOutput)
# read text, parsing as a json file
stationStatus <- apiData$data$stations
# extract a dataframe from a list object of R and save as 'stationStatus'
cols <- c('num_bikes_disabled','num_docks_disabled', 'station_id',
'num_ebikes_available', 'num_bikes_available', 'num_docks_available')
# save column names we are going to name the new dataframe
stationStatus = stationStatus[,cols]
# do the naming part
str(apiOutput)
str(apiData)
# The 'apiOutput' is pure text, saved as large characters
# The 'apiData' is a structured 'list' varaible of R
# prettify(apiOutput)
# This function makes the large character of original json file somewhat readable but still not enough, and due to the length of result showing, I'm going to mute it
str(stationStatus)
# This dataframe has the information of the numbers of different bikes, ebikes and docks available or not at each stations, identified by station_id. Only station_id is character while other factors are all saved as integer.
hist(stationStatus$num_docks_available)
hist(stationStatus$num_bikes_available)
# nrow(unique(stationStatus%>%filter(stationStatus$num_ebikes_available>=1)))
nrow(unique(stationStatus[stationStatus$num_ebikes_available>0,]))
station_1more_ebike=stationStatus[stationStatus$num_ebikes_available>=1,]
mean(station_1more_ebike$num_docks_available)
mean(stationStatus$num_docks_available)
# These two means are different with an absolute value of about 1
stationStatus$stationSize=stationStatus$num_ebikes_available+
stationStatus$num_bikes_available+
stationStatus$num_docks_available+
stationStatus$num_bikes_disabled+
stationStatus$num_docks_disabled
hist(stationStatus$stationSize)
stationStatus$occupied_docks=stationStatus$stationSize-stationStatus$num_docks_available-stationStatus$num_docks_disabled
stationStatus$Bike_all=stationStatus$num_ebikes_available+stationStatus$num_bikes_available
plot(stationStatus$occupied_docks,stationStatus$num_bikes_available)
# Occupied dock numbers are similar to available bike numbers
plot(stationStatus$occupied_docks,stationStatus$Bike_all)
# Occupied dock numbers are close to all bike available
library(ggplot2)
MyPlot <- ggplot(economics, aes(x=date))
myPlot <- MyPlot + geom_line(aes(y=psavert))
print(myPlot)
myplot_9=myplot_8+ylab('Rate')+xlab('Date')
# Enter your name here: Hang Tian
# 1. I did this lab assignment by myself, with help from the book and the professor.
library(ggplot2)
MyPlot <- ggplot(economics, aes(x=date))
myPlot <- MyPlot + geom_line(aes(y=psavert))
print(myPlot)
# just write the name or print it, the plot is saved in 'myPlot'
?economics
# That means personal savings rate
# Max happens at about 1975, min happens at about 2005
economics[economics$psavert==max(economics$psavert),]$date
economics[economics$psavert==min(economics$psavert),]$date
economics[which.max(economics$psavert),]$date
economics[which.min(economics$psavert),]$date
myPlot_green <- MyPlot + geom_line(aes(y=psavert),color='green')
myPlot_green
myplot_green_with_title=myPlot_green+ggtitle('Personal Savings Rate: 1967-2014')
myplot_green_with_title
myplot_gr_with_title=myplot_green_with_title+geom_line(aes(y=uempmed),color='red')
myplot_gr_with_title
myplot_8=myplot_gr_with_title+ggtitle('Personal savings rate and median duration of unemployment: 1967 - 2014')
myplot_8
myplot_9=myplot_8+ylab('Rate')+xlab('Date')
myplot_9
ggplot(economics)+geom_point(aes(x=unemploy,y=psavert,color=uempmed))
# There is a decreasing trend of personal savings rate as the number of unemployed in thousands increases. Meanwhile, median duration of unemployment drops clearly as the number of unemployed in thousands increases after it reaches 8000.
myplot_9=myplot_8+ylab('Rate')+xlab('Year')
myplot_9
ggplot(economics)+geom_point(aes(x=unemploy,y=psavert,color=uempmed))
ggplot(economics)+geom_point(aes(x=unemploy,y=psavert,color=uempmed))+
ylab('Personal savings rate')+xlab('median duration of unemployment')+
ggtitle('Personal savings rate and median duration of unemployment: 1967 - 2014')
ggplot(economics)+geom_point(aes(y=psavert,x=unemploy,color=uempmed))+
ylab('Personal savings rate')+xlab('median duration of unemployment')+
ggtitle('Personal savings rate and median duration of unemployment: 1967 - 2014')
ggplot(economics)+geom_point(aes(y=psavert,x=unemploy,color=uempmed))+
ylab('Personal savings rate')+xlab('median duration of unemployment')+
ggtitle('Personal savings rate and median duration of unemployment: 1967 - 2014')
install
install.libraries('rcmdr')
install.packages('rcmdr')
install.packages('Rcmdr',dependencies = TRUE)
library(rcmdr)
library(Rcmdr)
knitr::opts_chunk$set(echo = TRUE)
# Step 0. library packages, setting working directory and load data
# Library tidyverse
library(tidyverse)
# This package is used to read parquet files
library(arrow)
# Setting working directory, mute it and set it to your working file
setwd("~/1 Learning in US/Semester files Fall 2023/IST 687 Intro to DS/IST687_Project")
# Loading the processed static house table
static_house_original=read_parquet('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/static_house_info.parquet')
# Now in this dataset, model_table has all the data available for modeling, we might filter for just some of it, but I first made it.
load('ProjectData.RData')
model_table=model_table %>%
mutate_if(sapply(model_table, is.character), as.factor)
temp_table = model_table[,-c(1:44,46)]%>% select(where(~n_distinct(.) > 1))
unique(temp_table[,2])
temp_table=temp_table%>%as.data.frame()
lm_house=lm(total~.,data=temp_table)
na_count <-sapply(temp_table, function(y) sum(length(which(is.na(y)))))%>%data.frame()
View(na_count)
View(na_count)
row_list=which.na(tempt_table$in.sqft)
row_list=which(is.na(temp_table$in.sqft), arr.ind=TRUE)
row_list=which(is.na(temp_table$in.sqft), arr.ind=TRUE)%>%as.data.frame()
View(row_list)
model_table$bldg_id[row_list,]
bldg_ids=unique(model_table[row_list,1])
row_list=which(is.na(temp_table$in.sqft), arr.ind=TRUE)
bldg_ids=unique(model_table[row_list,1])
View(bldg_ids)
model_table[row_list,1]
bldg_ids=unique(model_table[row_list,2])
View(bldg_ids)
# Hang: This steps takes my whole afternoon, so I muted it just in case you guys run it by accident
# Form a table for data modeling
# a=1
# b=5710
# for (i in c(1:nrow(static_house_cleaned))[a:b]){
bldg_id=as.character(static_house_cleaned$bldg_id[1])
#   county=as.character(static_house_cleaned$county[i])
#   # Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
temp_energy_usage$bldg_id=as.numeric(bldg_id)
temp_energy_usage=temp_energy_usage%>%filter(month(time)==7)
temp_energy_usage=temp_energy_usage[,c(44,43,1:42)]
View(temp_energy_usage)
county=as.character(static_house_cleaned$county[1])
#   # Retrieve weather data
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[,c(1,9,2:8)]
View(temp_weather)
unique(model_table[,2])
# Now in this dataset, model_table has all the data available for modeling, we might filter for just some of it, but I first made it.
load('ProjectData.RData')
unique(model_table[,2])
#   # Form a table for data modeling (1 house included)
temp_1house=left_join(temp_energy_usage,temp_weather,by='time')
# Hang: This steps takes my whole afternoon, so I muted it just in case you guys run it by accident
# Form a table for data modeling
# a=1
# b=5710
# for (i in c(1:nrow(static_house_cleaned))[a:b]){
bldg_id=as.character(static_house_cleaned$bldg_id[1])
county=as.character(static_house_cleaned$county[1])
#   # Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
#   # Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
temp_energy_usage$bldg_id=as.numeric(bldg_id)
temp_energy_usage=temp_energy_usage%>%filter(month(time)==7)
temp_energy_usage=temp_energy_usage%>%filter(month(time)==7)
temp_energy_usage=temp_energy_usage[,c(44,43,1:42)]
temp_energy_usage$total=rowSums(temp_energy_usage[3:44])
#   # Retrieve weather data
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
#   # Retrieve weather data
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[,c(1,9,2:8)]
#   # Form a table for data modeling (1 house included)
temp_1house=left_join(temp_energy_usage,temp_weather,by='time')
temp_1house=left_join(temp_1house,static_house_cleaned[1,],by=c('bldg_id','county'))
View(temp_1house)
View(temp_1house)
# Form a table for data modeling (1 house included)
temp_1house=left_join(temp_energy_usage,temp_weather,by='time')
View(temp_1house)
View(temp_energy_usage)
View(temp_energy_usage)
temp_table=model_table[48,2]
View(temp_table)
temp_table=model_table[1:48,2]
View(temp_table)
temp_time=temp_weather$time
temp_time=rep(temp_weather$time,each=2)
temp_time=rep(temp_weather$time,each=5710)
model_table$time=temp_time
unique(model_table$time)
View(temp_weather)
temp_weather$time[1]
temp_weather$time[1]==temp_energy_usage$time[1]
temp_energy_usage$time[1]
load('ProjectData.RData')
# Step 0. library packages, setting working directory and load data
# Library tidyverse
library(tidyverse)
# This package is used to read parquet files
library(arrow)
# Setting working directory, mute it and set it to your working file
setwd("~/1 Learning in US/Semester files Fall 2023/IST 687 Intro to DS/IST687_Project")
# Loading the processed static house table
static_house_original=read_parquet('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/static_house_info.parquet')
load('ProjectData.RData')
load('ProjectData.RData')
unique(model_table$time)
?as.POSIXct
?tz
bldg_id=as.character(static_house_cleaned$bldg_id[i])
# Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
bldg_id=as.character(static_house_cleaned$bldg_id[1])
# Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
tz=tz(temp_energy_usage$time)
model_table$time=as.POSIXct(model_table$time,tz=tz)
unique(model_table$time)
county=as.character(static_house_cleaned$county[i])
county=as.character(static_house_cleaned$county[1])
# Retrieve weather data
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
View(temp_weather)
temp_weather$date_time=as.POSIXct(temp_weather$date_time,tz=tz)
View(temp_weather)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[,c(1,9,2:8)]
View(temp_weather)
unique(model_table$time)[1:4]
time_list=unique(model_table$time)[1:4]
remake_table=model_table%>%filter(time %in% time_list)
View(remake_table)
unique(model_table$time)
time_list=unique(model_table$time)[741:744]
remake_table=model_table%>%filter(time %in% time_list)
View(remake_table)
done_table=model_table%>%filter(!time %in% time_list)
View(remake_table)
remake_table=remake_table[,1:45]
check_table=static_house_cleaned[,c('bldg_id','county')]
View(check_table)
remake_table=left_join(remake_table,check_table,by='bldg_id')
View(remake_table)
county=unique(static_house_cleaned$county)
county=unique(static_house_cleaned$county)[1]
county=unique(static_house_cleaned$county)[1]
unique(static_house_cleaned$county)[1]
county=as.character(unique(static_house_cleaned$county)[1])
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather$date_time=as.POSIXct(temp_weather$date_time,tz=tz)
temp_weather$date_time=as.POSIXct(temp_weather$date_time,tz=tz)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[,c(1,9,2:8)]
View(temp_weather)
View(temp_weather)
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather$date_time=as.POSIXct(temp_weather$date_time,tz=tz)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[741:744,c(1,9,2:8)]
View(temp_weather)
View(temp_weather)
if (i==1){
weather=temp_weather
}else{weather=rbind(weather,temp_weather)}
for (i in c(1:46)){
county=as.character(unique(static_house_cleaned$county)[i])
temp_weather=read_csv(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/weather/2023-weather-data/',county,'.csv',sep=''),show_col_types = FALSE)
temp_weather$date_time=as.POSIXct(temp_weather$date_time,tz=tz)
temp_weather=temp_weather%>%filter(month(date_time)==7)
temp_weather=temp_weather%>%rename(time=date_time)
temp_weather$county=county
temp_weather=temp_weather[741:744,c(1,9,2:8)]
if (i==1){
weather=temp_weather
}else{weather=rbind(weather,temp_weather)}
}
View(weather)
View(temp_weather)
View(temp_energy_usage)
bldg_id=as.character(static_house_cleaned$bldg_id[1])
# Retrieve energy data
temp_energy_usage=read_parquet(paste('https://intro-datascience.s3.us-east-2.amazonaws.com/SC-data/2023-houseData/',bldg_id,'.parquet',sep=''))
temp_energy_usage$bldg_id=as.numeric(bldg_id)
tz=tz(temp_energy_usage$time)
temp_energy_usage=temp_energy_usage%>%filter(month(time)==7)
temp_energy_usage=temp_energy_usage[,c(44,43,1:42)]
temp_energy_usage$total=rowSums(temp_energy_usage[3:44])
View(temp_energy_usage)
View(weather)
temp_table=left_join(remake_table,weather,by=c('time','county'))
temp_table=left_join(temp_table,static_house_cleaned,by=c('bldg_id','county'))
View(temp_table)
model_table=rbind(temp_table,done_table)
temp_table=temp_table %>%
mutate_if(sapply(temp_table, is.character), as.factor)
model_table=rbind(temp_table,done_table)
temp_done_table=done_table %>%
mutate_if(sapply(done_table, is.factor), as.character)
model_table=rbind(temp_table,temp_done_table)
View(temp_done_table)
?is.factor
glimpse(temp_done_table)
model_table=model_table%>%arrange(bldg_id,time)
na_count <-sapply(model_table, function(y) sum(length(which(is.na(y)))))%>%as.data.frame()
View(na_count)
model_table=model_table %>%
mutate_if(sapply(model_table, is.character), as.factor)
na_count <-sapply(model_table, function(y) sum(length(which(is.na(y)))))%>%as.data.frame()
View(na_count)
glimpse(model_table)
View(na_count)
unique(static_house_cleaned)
unique(static_house_cleaned$in.cooling_setpoint)
temp_house=static_house_cleaned %>% slice(rep(1:n(), each = 2))
View(temp_house)
temp_house=static_house_cleaned %>% slice(rep(1:n(), each = 744))
model_table$in.cooling_setpoint=temp_house$in.cooling_setpoint
unique(model_table$in.cooling_setpoint)
model_table$in.heating_setpoint=temp_house$in.heating_setpoint
model_table$upgrade.insulation_roof=temp_house$upgrade.insulation_roof
model_table$upgrade.infiltration_reduction=temp_house$upgrade.infiltration_reduction
model_table$upgrade.insulation_ceiling=temp_house$upgrade.insulation_ceiling
model_table$upgrade.ducts=temp_house$upgrade.ducts
model_table$upgrade.hvac_heating_type=temp_house$upgrade.hvac_heating_type
model_table$upgrade.insulation_wall=temp_house$upgrade.insulation_wall
model_table=model_table %>%
mutate_if(sapply(model_table, is.character), as.factor)
na_count <-sapply(model_table, function(y) sum(length(which(is.na(y)))))%>%as.data.frame()
rm(check_table,done_table,na_count,remake_table,temp_done_table,temp_energy_usage,temp_house,
temp_table,temp_weather,weather)
rm(bldg_id,county,i,time_list,tz)
View(model_table)
save.image("~/1 Learning in US/Semester files Fall 2023/IST 687 Intro to DS/IST687_Project/ProjectData_10.29.RData")
View(model_table)
colnames(model_table)
lm_model=lm(total~.,data=model_table[,-c(3:44,1,46)])
colnames(model_table)
# Vector memory exhausted if you run this
# lm_model=lm(total~.,data=model_table[,-c(3:44,1,46)])
knitr::opts_chunk$set(echo = TRUE)
?upper.tri
library(Rcmdr)
library(Rcmrd)
library(Rcmdr)
library(Rcmdr)
# Enter your name here: Hang Tian
numbers=c(1,2,3,4,5)
sd(numbers)
summary(numbers)
# Enter your name here: Hang Tian
range(numbser)
# Enter your name here: Hang Tian
range(numbsers)
# Enter your name here: Hang Tian
range(numbers)
# Enter your name here: Hang Tian
min(numbers)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
mpa_df=read_csv('https://intro-datascience.s3.us-east-2.amazonaws.com/stateRatingExam.csv')
# This data only gives the center location, so if we want to plot a polygon, this is not useful unless the circle
library(ggplot2); library(maps); library(ggmap); library(mapproj)
us <- map_data("state")
# call us state level GIS data, save as 'us'
us$state_name <- tolower(us$region)
# lowercase us$region
map <- ggplot(us, aes(map_id= state_name,x=long, y=lat, group=group))+
geom_polygon(fill = "white", color = "green") + expand_limits(x=us$long, y=us$lat)+
coord_map() +
ggtitle('My Map Viz: Hang Tian, htian20@sry.edu')
map
View(mpa_df)
View(mpa_df)
library(tidyverse)
# This data only gives the center location, so if we want to plot a polygon, this is not useful unless the circle
library(ggplot2); library(maps); library(ggmap); library(mapproj)
View(mpa_df)
ggplot(map_df)+geom_polygon(aes(x=stateCenterX,y=stateCenterY))
ggplot(data=map_df)+geom_polygon(aes(x=stateCenterX,y=stateCenterY))
map_df=read_csv('https://intro-datascience.s3.us-east-2.amazonaws.com/stateRatingExam.csv')
ggplot(data=map_df)+geom_polygon(aes(x=stateCenterX,y=stateCenterY))
ggplot(data=map_df)+geom_path(aes(x=stateCenterX,y=stateCenterY))
View(map_df)
ggplot(data=map_df)+geom_path(aes(x=stateCenterX,y=stateCenterY,color=funRating))
View(map_df)
ggplot(map_df, aes(x = State, y = funRating)) +
geom_point(aes(fill = State), shape = 21, size = 4) +
scale_fill_discrete(guide = FALSE) +
labs(title = "Rating by State", x = "State", y = "Rating") +
theme_minimal()
View(map)
View(map_df)
ggplot(map_df, aes(x = stateNameInUSA, y = funRating)) +
geom_point(aes(fill = State), shape = 21, size = 4) +
scale_fill_discrete(guide = FALSE) +
labs(title = "Rating by State", x = "State", y = "Rating") +
theme_minimal()
ggplot(map_df, aes(x = stateNameInUSA, y = funRating)) +
geom_point(aes(fill = stateNameInUSA), shape = 21, size = 4) +
scale_fill_discrete(guide = FALSE) +
labs(title = "Rating by State", x = "State", y = "Rating") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
map_df=read_csv('https://intro-datascience.s3.us-east-2.amazonaws.com/stateRatingExam.csv')
# This data only gives the center location, so if we want to plot a polygon, this is not useful unless the circle, but I don't know how to do that
library(ggplot2); library(maps); library(ggmap); library(mapproj)
us <- map_data("state")
# call us state level GIS data, save as 'us'
us$state_name <- tolower(us$region)
# lowercase us$region
map <- ggplot(us, aes(map_id= state_name,x=long, y=lat, group=group))+
geom_polygon(fill = "white", color = "green") + expand_limits(x=us$long, y=us$lat)+
coord_map() +
ggtitle('My Map Viz: Hang Tian, htian20@sry.edu')
map
setwd("~/Documents/1 Learning in US/Semester files Fall 2023/IST 687 Intro to DS/IST687_Project")
knitr::opts_chunk$set(echo = TRUE)
# Setting working directory, mute it and set it to your working file
# Shahukaru:
# setwd("/Users/r.shahukaru/Desktop/IST 687/Project")
# Hang:
setwd("~/Documents/1 Learning in US/Semester files Fall 2023/IST 687 Intro to DS/IST687_Project")
house_exclude_list=c()
for (i in c(1:ncol(static_house_original))) {
if (length(unique(static_house_original[,i]))==1){
house_exclude_list=c(house_exclude_list,i)
}
rm(i)
}
library(caret)
set.seed(222)
trainlist=createDataPartition(y=model_table$total,p=0.6,list=FALSE)
# library(caret)
# set.seed(222)
# trainlist=createDataPartition(y=model_table$total,p=0.6,list=FALSE)
# train_set=model_table[trainlist,]
# test_set=model_table[-trainlist,]
#
#
# lm_model=lm(total~.,data=train_set[,-c(1:44)])
# lm_model_info=summary(lm_model)
# lm_model_table=lm_model_info$coefficients%>%data.frame()
# lm_model_info
